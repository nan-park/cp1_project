{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM1NekuFNppBf3iwGI3F49+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nan-park/cp1_project/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **0과 1을 분류하는 인공신경망 프로그래밍**"
      ],
      "metadata": {
        "id": "2K4TxCWwuRNn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Import**"
      ],
      "metadata": {
        "id": "3lAvzFhkmi4r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# (체크) vscode에 주석 달았던 것들 나중에 colab에도 옮겨놓기"
      ],
      "metadata": {
        "id": "fnhdgXKOvEJ1"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "TZZbeiymmbbs"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import csv"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Load**"
      ],
      "metadata": {
        "id": "hTwHDU2wuVyu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive  # google drive mount\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eHH52vxqSr2l",
        "outputId": "f34c26ee-7a35-4d5e-f952-cb54cbd25945"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 불러오기\n",
        "def data_load():\n",
        "  df = pd.read_csv('/content/drive/MyDrive/binary_dataset.csv')\n",
        "  return df\n",
        "# df = data_load()"
      ],
      "metadata": {
        "id": "0ARZrNC-mq75"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df.head()"
      ],
      "metadata": {
        "id": "2htdCuKloOKi"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Split**"
      ],
      "metadata": {
        "id": "SxW1RzSuudd2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습/테스트 데이터 뒤섞기\n",
        "def df_shuffle(df):\n",
        "  return df.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "# 특성, 타겟 나누기\n",
        "def divide_xy(df):\n",
        "  target = 'y'\n",
        "  features = list(df.columns)\n",
        "  features.remove(target)\n",
        "\n",
        "  X = df[features]\n",
        "  y = np.array(df[target]).reshape(-1, 1)\n",
        "  return X, y\n",
        "\n",
        "# 학습/테스트 데이터 분리하기\n",
        "def train_test_divide(X, y, test_size=0.2):  # X: pandas dataframe, y: numpy array\n",
        "  length = len(y)\n",
        "  test_index = int(length * test_size)\n",
        "\n",
        "  X_test = X[:test_index]\n",
        "  y_test = y[:test_index]\n",
        "\n",
        "  X_train = X[test_index:]  \n",
        "  y_train = y[test_index:]\n",
        "\n",
        "  return X_train, y_train, X_test, y_test"
      ],
      "metadata": {
        "id": "qxfruCayo0eh"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 위의 함수 통합\n",
        "def train_test_split(df, shuffle=True, test_size=0.2):\n",
        "  if shuffle:\n",
        "    df = df_shuffle(df)\n",
        "  \n",
        "  X, y = divide_xy(df)\n",
        "  return train_test_divide(X, y, test_size=test_size)\n",
        "\n",
        "# X_train, y_train, X_test, y_test = train_test_split(df)"
      ],
      "metadata": {
        "id": "EndvpVrA-s4M"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 미니배치 설정\n",
        "def split_mini_batch(X, y, n): # train, test 들어올 예정\n",
        "  # 4개씩 미니배치 설정. 나머지는 버리기\n",
        "  length = len(y)\n",
        "  num = length // n # 미니배치 개수\n",
        "  X_batch_list = []\n",
        "  y_batch_list = []\n",
        "  for i in range(num):\n",
        "    i = i * n\n",
        "    # 비복원 추출. 데이터가 적기 때문에 겹치지 않는 게 나을 듯.\n",
        "    X_batch_list.append(X[i:i+n]) # index: 0~4, 4~8, 8~12, ...\n",
        "    y_batch_list.append(y[i:i+n])\n",
        "  return X_batch_list, y_batch_list\n",
        "\n",
        "# X_batch_list, y_batch_list = set_mini_batch(X_train, y_train)"
      ],
      "metadata": {
        "id": "0NhRSsqyIoaS"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Weight and Bias Initialization**"
      ],
      "metadata": {
        "id": "fLPARQmRugzE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Xavier 초기화(활성화함수가 시그모이드일 때 잘 동작), 편향 포함한 후에 분리하기\n",
        "# 이전 층 노드 개수가 n, 현재 층 노드 개수 m일 때, 표준편차가 2/루트(n+m)인 정규분포로 초기화\n",
        "\n",
        "def initialize_parameter(n, m):\n",
        "  init = np.random.normal(0, 2/((n+m)**2), (n+1, m))\n",
        "  W = init[:-1, :]\n",
        "  b = init[-1, :]\n",
        "  return W, b\n",
        "\n",
        "# initialize_parameter(4, 5)"
      ],
      "metadata": {
        "id": "FVqeboILdV0B"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(x):\n",
        "    return 1 / (1 +np.exp(-x))\n",
        "\n",
        "def classification(x):\n",
        "  if x < 0.5:\n",
        "    return 0\n",
        "  else:\n",
        "    return 1"
      ],
      "metadata": {
        "id": "5JHGJwwgBCLL"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Sequential Layers**"
      ],
      "metadata": {
        "id": "jwpSoZNzuvrN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Layer():  # 은닉층, 출력층\n",
        "  def __init__(self, node_num, activation='linear'):\n",
        "    self.node_num = node_num\n",
        "    self.activation = activation\n",
        "    self.prev = None\n",
        "    self.next = None\n",
        "\n",
        "  def set_weights(self):\n",
        "    if self.prev is not None:\n",
        "      prev_node_num = self.prev.node_num\n",
        "      self.W, self.b = initialize_parameter(prev_node_num, self.node_num)\n",
        "  \n",
        "  @property\n",
        "  def X(self):\n",
        "    return self._X\n",
        "  @X.setter\n",
        "  def X(self, value):\n",
        "    self._X = value\n",
        "\n",
        "class Dense(Layer):\n",
        "  def __init__(self, node_num, activation='linear'):\n",
        "    # super().__init__(self, node_num)\n",
        "    self.node_num = node_num\n",
        "    self.activation = activation\n",
        "    self.prev = None\n",
        "    self.next = None\n",
        "  \n",
        "  def output(self):\n",
        "    answer = np.dot(self._X, self.W) + self.b\n",
        "    if self.activation == 'linear':\n",
        "      return answer\n",
        "    elif self.activation == 'sigmoid':\n",
        "      answer = sigmoid(answer)\n",
        "      # classify = np.vectorize(classification)\n",
        "      # return classify(answer)\n",
        "      return answer\n",
        "\n",
        "class Input(Layer): # prev가 없음\n",
        "  def __init__(self, node_num, activation='linear'):\n",
        "    self.node_num = node_num\n",
        "    self.activation = activation\n",
        "    self.prev = None\n",
        "    self.next = None\n",
        "\n",
        "  def output(self):\n",
        "    return self._X"
      ],
      "metadata": {
        "id": "6OZ0YaOUka_n"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sequential([])에 layer 쌓고 서로 연결되도록 하기. 가중치 초기화 가능해야 함\n",
        "class Sequential():\n",
        "  def __init__(self, layer_list):\n",
        "    if len(layer_list)==0:\n",
        "      self.head = None\n",
        "      self.tail = None\n",
        "    elif len(layer_list)==1:\n",
        "      self.head = layer_list[0]\n",
        "      self.tail = layer_list[0]\n",
        "    else:\n",
        "      self.head = layer_list[0]\n",
        "      iterator = self.head\n",
        "      for layer in layer_list[1:-1]:\n",
        "        layer.prev= iterator\n",
        "        iterator.next = layer\n",
        "        iterator = layer\n",
        "      iterator.next = layer_list[-1]\n",
        "      self.tail = layer_list[-1]\n",
        "      self.tail.prev = iterator\n",
        "\n",
        "    # 가중치, 편향 초기화\n",
        "    iterator = self.head\n",
        "    while iterator:\n",
        "      iterator.set_weights()\n",
        "      iterator = iterator.next\n",
        "\n",
        "  @property\n",
        "  def input(self):\n",
        "    return self._input\n",
        "  @input.setter\n",
        "  def input(self, value):\n",
        "    self._input = value\n",
        "    self.head.X = value\n",
        "\n",
        "  def output(self):\n",
        "    iterator = self.head  # Input\n",
        "    while iterator.next:\n",
        "      iterator.next.X = iterator.output()\n",
        "      iterator = iterator.next\n",
        "    return iterator.output()\n",
        "    "
      ],
      "metadata": {
        "id": "jVSnp3_GoODD"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model = Sequential([Input(8), Dense(16), Dense(32), Dense(1, activation='sigmoid')])"
      ],
      "metadata": {
        "id": "3QmP3JdVbBzY"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Predict and Evaluate**"
      ],
      "metadata": {
        "id": "aCOSJWptu1im"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(X_batch, y_batch, model):\n",
        "    model.input = X_batch\n",
        "    y_pred_prob = model.output()\n",
        "    return y_pred_prob\n",
        "\n",
        "\n",
        "def evaluate(X_batch_list, y_batch_list, model):\n",
        "    def accuracy(y_pred, y_batch):\n",
        "        return sum(y_pred == y_batch)[0] / y_pred.shape[0]\n",
        "\n",
        "    def cross_entropy(y_pred_prob, y_batch):\n",
        "        delta = 1e-7\n",
        "        return -np.sum(y_batch * np.log(y_pred_prob + delta)) / y_batch.shape[0]  # (체크)\n",
        "\n",
        "    def classification(x):\n",
        "        if x < 0.5:\n",
        "            return 0\n",
        "        else:\n",
        "            return 1\n",
        "\n",
        "    accuracy_list = []\n",
        "    cross_entropy_list = []\n",
        "    classify = np.vectorize(classification)\n",
        "    for i in range(len(X_batch_list)):  # (체크) evaluate 기능만 남겨두고 다시 메서드화하기\n",
        "        X_batch = X_batch_list[i]\n",
        "        y_batch = y_batch_list[i]\n",
        "        y_pred_prob = predict(X_batch, y_batch, model)\n",
        "        y_pred = classify(y_pred_prob)\n",
        "\n",
        "        accuracy_list.append(accuracy(y_pred, y_batch))\n",
        "        cross_entropy_list.append(cross_entropy(y_pred_prob, y_batch))\n",
        "\n",
        "    accuracy = np.mean(accuracy_list)\n",
        "    cross_entropy = np.mean(cross_entropy_list)\n",
        "    return accuracy, cross_entropy\n"
      ],
      "metadata": {
        "id": "CK9B-SGXGJGm"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Main**"
      ],
      "metadata": {
        "id": "2P2zb8-uu47c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "  df = data_load()\n",
        "  X_train, y_train, X_test, y_test = train_test_split(df)\n",
        "  X_batch_list, y_batch_list = split_mini_batch(X_train, y_train, 4) # train 데이터만\n",
        "  model = Sequential([Input(8), Dense(16), Dense(32), Dense(1, activation='sigmoid')])\n",
        "  accuracy, cross_entropy = evaluate(X_batch_list, y_batch_list, model)\n",
        "  print(f\"[Epoch 1] TrainData - Loss = {round(cross_entropy, 3)}, Accuracy = {round(accuracy, 3)}\")\n",
        "\n",
        "main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_zjG7ooPQVJ7",
        "outputId": "8b7ecbdf-87ca-470d-feec-106433d86583"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 1] TrainData - Loss = 0.173, Accuracy = 0.25\n"
          ]
        }
      ]
    }
  ]
}